{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check which transcripts are missing, but have images/audios - to generate a dataset where each video has the images, audio and text features along with targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "courses_dir = '/home/anish17281/NLP_Dataset/dataset/'\n",
    "\n",
    "# Get sorted list of all courses (excluding any files)\n",
    "dirlist = []\n",
    "for fname in os.listdir(courses_dir):\n",
    "    if os.path.isdir(os.path.join(courses_dir, fname)):\n",
    "        dirlist.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course 1\n",
      "Processing course 2\n",
      "Processing course 3\n",
      "Processing course 4\n",
      "Processing course 5\n",
      "Processing course 6\n",
      "Processing course 7\n",
      "Processing course 8\n",
      "Processing course 9\n",
      "Processing course 10\n",
      "Processing course 11\n",
      "Processing course 12\n",
      "Processing course 13\n",
      "Processing course 14\n",
      "Processing course 15\n",
      "Processing course 16\n",
      "Processing course 17\n",
      "Processing course 18\n",
      "Processing course 19\n",
      "Processing course 20\n",
      "Processing course 21\n",
      "Processing course 22\n",
      "Processing course 23\n",
      "Processing course 24\n"
     ]
    }
   ],
   "source": [
    "vids = set()\n",
    "trs = set()\n",
    "gts = set()\n",
    "audios = set()\n",
    "\n",
    "for course_num in sorted(dirlist, key=int):\n",
    "    print(\"Processing course \" + str(course_num))\n",
    "    for vid in os.listdir(os.path.join(courses_dir, course_num, 'videos')):\n",
    "        if 'mp4' not in vid or '_' in vid:\n",
    "            continue\n",
    "        vids.add('{}/{}'.format(course_num, vid[:-4]))\n",
    "    \n",
    "    for audio in os.listdir(os.path.join(courses_dir, course_num, 'audio-features')):\n",
    "        if 'pkl' not in audio or '_' in audio:\n",
    "            continue\n",
    "        audios.add('{}/{}'.format(course_num, audio[:-4]))\n",
    "    \n",
    "    for tr in os.listdir(os.path.join(courses_dir, course_num, 'transcripts')):\n",
    "        if 'txt' not in tr or '_' in tr:\n",
    "            continue\n",
    "        trs.add('{}/{}'.format(course_num, tr[:-4]))\n",
    "    \n",
    "    for gt in os.listdir(os.path.join(courses_dir, course_num, 'ground-truth')):\n",
    "        if 'txt' not in gt or '_' in gt:\n",
    "            continue\n",
    "        gts.add('{}/{}'.format(course_num, gt[:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 965, 961, 961)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vids), len(audios), len(trs), len(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter = vids.intersection(audios).intersection(trs).intersection(gts)\n",
    "len(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "with open('dataset_inter.pkl', 'wb') as f:\n",
    "    pickle.dump(inter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "with open('dataset_inter2.pkl', 'rb') as f:\n",
    "    dataset_inter = pickle.load(f)\n",
    "\n",
    "if '22/2' in dataset_inter:\n",
    "    dataset_inter.remove('22/2')\n",
    "\n",
    "if '22/4' in dataset_inter:\n",
    "    dataset_inter.remove('22/4')\n",
    "\n",
    "if '22/7' in dataset_inter:\n",
    "    dataset_inter.remove('22/7')\n",
    "\n",
    "len(dataset_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "with open('dataset_inter2.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset_inter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import TextDataset, ImageDataset, AudioDataset, TargetDataset\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding_dir = '/home/anish17281/NLP_Dataset/dataset/'\n",
    "train_text_loader = torch.utils.data.DataLoader(TextDataset(text_embedding_dir, 405), batch_size = 1, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(256), transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize,])\n",
    "\n",
    "image_dir = '/home/anish17281/NLP_Dataset/dataset/'\n",
    "train_image_loader = torch.utils.data.DataLoader(ImageDataset(image_dir, transform), batch_size = 1, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = '/home/anish17281/NLP_Dataset/dataset/'\n",
    "train_audio_loader = torch.utils.data.DataLoader(AudioDataset(audio_dir), batch_size = 1, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_dir = '/home/anish17281/NLP_Dataset/dataset/'\n",
    "train_target_loader = torch.utils.data.DataLoader(TargetDataset(courses_dir), batch_size = 1, shuffle = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_image_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_audio_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_target_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(961, 961)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_target_loader.dataset.target_sentences_path), len(train_target_loader.dataset.source_sentences_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train, test indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import AudioDataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "courses_dir = '/home/anish17281/NLP_Dataset/dataset/'\n",
    "dataset = AudioDataset(courses_dir)\n",
    "\n",
    "with open('none_idxs.pkl', 'rb') as f:\n",
    "    none_idxs = pickle.load(f)\n",
    "\n",
    "test_split = 0.1\n",
    "shuffle_dataset = True\n",
    "dataset_size = len(dataset)\n",
    "indices = [idx for idx in range(dataset_size) if idx not in none_idxs]\n",
    "split = int(np.floor(test_split * len(indices)))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = set(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25,\n",
       " 33,\n",
       " 42,\n",
       " 49,\n",
       " 70,\n",
       " 75,\n",
       " 78,\n",
       " 80,\n",
       " 94,\n",
       " 104,\n",
       " 128,\n",
       " 144,\n",
       " 145,\n",
       " 173,\n",
       " 183,\n",
       " 201,\n",
       " 207,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 224,\n",
       " 227,\n",
       " 248,\n",
       " 253,\n",
       " 256,\n",
       " 259,\n",
       " 263,\n",
       " 276,\n",
       " 290,\n",
       " 300,\n",
       " 308,\n",
       " 314,\n",
       " 328,\n",
       " 331,\n",
       " 333,\n",
       " 335,\n",
       " 339,\n",
       " 345,\n",
       " 364,\n",
       " 367,\n",
       " 374,\n",
       " 437,\n",
       " 452,\n",
       " 457,\n",
       " 470,\n",
       " 480,\n",
       " 481,\n",
       " 496,\n",
       " 498,\n",
       " 508,\n",
       " 509,\n",
       " 541,\n",
       " 543,\n",
       " 546,\n",
       " 547,\n",
       " 563,\n",
       " 574,\n",
       " 590,\n",
       " 599,\n",
       " 602,\n",
       " 604,\n",
       " 648,\n",
       " 658,\n",
       " 666,\n",
       " 671,\n",
       " 681,\n",
       " 684,\n",
       " 695,\n",
       " 698,\n",
       " 701,\n",
       " 704,\n",
       " 730,\n",
       " 732,\n",
       " 739,\n",
       " 752,\n",
       " 759,\n",
       " 768,\n",
       " 774,\n",
       " 789,\n",
       " 790,\n",
       " 825,\n",
       " 827,\n",
       " 839,\n",
       " 848,\n",
       " 851,\n",
       " 878,\n",
       " 890,\n",
       " 894,\n",
       " 895,\n",
       " 909,\n",
       " 910,\n",
       " 922,\n",
       " 959}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('test_indices.pkl', 'wb') as f:\n",
    "    pickle.dump(test_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
